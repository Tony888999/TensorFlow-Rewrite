import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from abc import ABC, abstractmethod

# Define the FBSNN class
class FBSNN(ABC):
    def __init__(self, Xi, T, M, N, D, layers):
        self.Xi = tf.convert_to_tensor(Xi, dtype=tf.float32)
        self.T = T
        self.M = M
        self.N = N
        self.D = D
        self.layers = layers

        # Initialize the neural network using tf.keras.Sequential
        self.model = self.build_neural_net(layers)

        # Optimizer
        self.optimizer = tf.keras.optimizers.Adam()

    def build_neural_net(self, layers):
        model = tf.keras.Sequential()
        model.add(tf.keras.layers.InputLayer(input_shape=(self.D + 1,)))

        # Hidden layers with sine activation functions
        for width in layers[1:-1]:
            model.add(tf.keras.layers.Dense(width, activation=tf.math.sin))

        # Output layer without activation
        model.add(tf.keras.layers.Dense(layers[-1], activation=None))
        return model

    def neural_net(self, X):
        return self.model(X)

    def net_u(self, t, X):
        with tf.GradientTape() as tape:
            tape.watch(X)
            u = self.neural_net(tf.concat([t, X], axis=1))
        Du = tape.gradient(u, X)
        return u, Du

    def Dg_tf(self, X):
        with tf.GradientTape() as tape:
            tape.watch(X)
            g = self.g_tf(X)
        Dg = tape.gradient(g, X)
        return Dg

    def loss_function(self, t, W):
        loss = 0
        X_list = []
        Y_list = []

        t0 = t[:, 0, :]
        W0 = W[:, 0, :]
        X0 = tf.tile(self.Xi, [tf.shape(t)[0], 1])
        Y0, Z0 = self.net_u(t0, X0)

        X_list.append(X0)
        Y_list.append(Y0)

        for n in range(self.N):
            t1 = t[:, n + 1, :]
            W1 = W[:, n + 1, :]
            dt = t1 - t0
            dW = W1 - W0

            mu = self.mu_tf(t0, X0, Y0, Z0)
            sigma = self.sigma_tf(t0, X0, Y0)

            sigma_dW = tf.matmul(sigma, tf.expand_dims(dW, -1))
            sigma_dW = tf.squeeze(sigma_dW, axis=-1)

            X1 = X0 + mu * dt + sigma_dW
            phi = self.phi_tf(t0, X0, Y0, Z0)
            sigma_Z_dW = tf.reduce_sum(Z0 * sigma_dW, axis=1, keepdims=True)
            Y1_tilde = Y0 + phi * dt + sigma_Z_dW

            Y1, Z1 = self.net_u(t1, X1)
            loss += tf.reduce_mean(tf.square(Y1 - Y1_tilde))

            t0 = t1
            W0 = W1
            X0 = X1
            Y0 = Y1
            Z0 = Z1

            X_list.append(X0)
            Y_list.append(Y0)

        loss += tf.reduce_mean(tf.square(Y1 - self.g_tf(X1)))
        loss += tf.reduce_mean(tf.square(Z1 - self.Dg_tf(X1)))

        X = tf.stack(X_list, axis=1)
        Y = tf.stack(Y_list, axis=1)

        Y0_pred = Y_list[0]

        return loss, X, Y, Y0_pred

    def fetch_minibatch(self):
        dt = self.T / self.N
        t = np.linspace(0, self.T, self.N + 1)
        t = np.tile(t.reshape(1, -1, 1), (self.M, 1, 1)).astype(np.float32)

        dW = np.sqrt(dt) * np.random.randn(self.M, self.N + 1, self.D).astype(np.float32)
        dW[:, 0, :] = 0
        W = np.cumsum(dW, axis=1)
        return t, W

    def train(self, N_Iter, learning_rate_schedule=None):
        for it in range(N_Iter):
            if learning_rate_schedule is not None:
                lr = learning_rate_schedule(it)
                self.optimizer.learning_rate.assign(lr)

            t_batch, W_batch = self.fetch_minibatch()

            with tf.GradientTape() as tape:
                loss_value, _, _, Y0_pred = self.loss_function(t_batch, W_batch)

            grads = tape.gradient(loss_value, self.model.trainable_variables)
            self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))

            if it % 10 == 0:
                print(f'It: {it}, Loss: {loss_value.numpy():.3e}, Y0: {tf.reduce_mean(Y0_pred).numpy():.3f}, Learning Rate: {self.optimizer.learning_rate.numpy():.1e}')

    def predict(self, Xi_star, t_star, W_star):
        Xi_star = tf.convert_to_tensor(Xi_star, dtype=tf.float32)
        t_star = tf.convert_to_tensor(t_star, dtype=tf.float32)
        W_star = tf.convert_to_tensor(W_star, dtype=tf.float32)

        _, X_pred, Y_pred, _ = self.loss_function(t_star, W_star)
        return X_pred.numpy(), Y_pred.numpy()

    @abstractmethod
    def phi_tf(self, t, X, Y, Z):
        pass

    @abstractmethod
    def g_tf(self, X):
        pass

    @abstractmethod
    def mu_tf(self, t, X, Y, Z):
        pass

    @abstractmethod
    def sigma_tf(self, t, X, Y):
        pass
